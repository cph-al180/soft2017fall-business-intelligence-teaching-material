{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will classify data into negative and positive statements\n",
    "Before you continue, please make sure that you have nltk installed\n",
    "http://www.nltk.org/\n",
    "\n",
    "If everything is setup correctly, the below cell should run without errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by using a text dataset from sklearn\n",
    "# This dataset contain around 18000 emails from a newsgroup\n",
    "# http://scikit-learn.org/stable/datasets/twenty_newsgroups.html\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll start using VADER\n",
    "# For that you first have to download and install NLTK\n",
    "# When you did that, run these two lines of code to fetch\n",
    "# the vader lexicon it'll need to classify negative/positive words\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create our sentiment analyser!\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "model = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using model.polarity_scores() give VADER a string\n",
    "# from the newsgroup and print the results\n",
    "# What do the numbers mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cool! Now we can see how happy something is.\n",
    "# Now extract the scores for each email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good job! But it's a little confusing with all those numbers...\n",
    "# Let's make it simpler by reducing all that data into 'H' and 'N'.\n",
    "# 'H' if the post is more happy than negative, and 'N' if the\n",
    "# post is more negative than happy.\n",
    "# Put this as an additional column in your pandas data frame.\n",
    "# We can know whether something is happy if the compound >= 0.\n",
    "# Similarly an email is negative if the compound < 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: You can use the pandas .assign method\n",
    "# http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.assign.html\n",
    "scores = [model.polarity_scores(t) for t in data[\"data\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll start to analyse the text and actually classify which category the\n",
    "text was contained in, based on the content of the emails. So we will have\n",
    "to predict a categorical variable, given some text.\n",
    "\n",
    "You probably noticed that the emails contains a \"target\" variable as well. This\n",
    "is a number, indicating what category the email is about. This is our predicting\n",
    "variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we have to transform text into something we can work\n",
    "# with (... numbers of course!! we love numbers!)\n",
    "# Import the TfidfVectorizer below and instantiate a new vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have a vectorizer we have to fit it to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and finally we have to use the vectorizer to transform\n",
    "# our text into high-dimensional vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the shape of the vector - what are you seeing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have a representation of text we can actually\n",
    "# work with (numbers!), we can start to classify the category\n",
    "# Start by importing the KMeans clustering algorithm and\n",
    "# instantiate a new KMeans model - remember to set the \n",
    "# numbers of clusters with n_clusters=X !\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that you have the KMeans classifier, fit it to your\n",
    "# tfidf vectors as your input (X) and the actual target\n",
    "# category as your output (y)\n",
    "# Hint: Instead of creating all these models one by one\n",
    "# you can create them as a single pipeline instead\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we have to figure out how well that went.\n",
    "# Use the accuracy_score to see how many categories we\n",
    "# got right!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
